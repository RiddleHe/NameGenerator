{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wcsowg-v1LS"
      },
      "outputs": [],
      "source": [
        "%run model.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load data and preprocess the dataset\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "words = open('names.txt', 'r').read().splitlines()\n",
        "\n",
        "# build vocabulary\n",
        "chars = sorted(list(set(\"\".join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi[\".\"]=0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "\n",
        "# shuffle the data\n",
        "import random\n",
        "random.seed(42)\n",
        "random.shuffle(words)\n",
        "\n",
        "# build dataset\n",
        "\n",
        "context_size = 8\n",
        "\n",
        "def build_dataset(files):\n",
        "  X,Y = [], []\n",
        "  for file in files:\n",
        "    context = [0]*context_size\n",
        "    for ch in file+\".\":\n",
        "      ix = stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      context = context[1:] + [ix]\n",
        "  X = torch.tensor(X, device=device)\n",
        "  Y = torch.tensor(Y, device=device)\n",
        "  return X,Y\n",
        "\n",
        "x1 = int(len(words)*0.8)\n",
        "x2 = int(len(words)*0.9)\n",
        "\n",
        "\n",
        "Xtr, Ytr = build_dataset(words[:x1])\n",
        "Xval, Yval = build_dataset(words[x1:x2])\n",
        "Xtest, Ytest = build_dataset(words[x2:])"
      ],
      "metadata": {
        "id": "OAF9GhuF1fPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voc_size = 27\n",
        "n_emb = 10\n",
        "n_hidden = 60\n",
        "\n",
        "model = Sequential(\n",
        "    [Embedding(voc_size, n_emb),\n",
        "     Flatten(2), Linear(n_emb*2, n_hidden), BatchNorm1d(n_hidden), Tanh(),\n",
        "     Flatten(2), Linear(n_hidden*2, n_hidden), BatchNorm1d(n_hidden), Tanh(),\n",
        "     Flatten(2), Linear(n_hidden*2, n_hidden), BatchNorm1d(n_hidden), Tanh(),\n",
        "     Linear(n_hidden, voc_size), ]\n",
        ")"
      ],
      "metadata": {
        "id": "7qo5Ry4j1lgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  model.layers[-1].weights *= 0.1\n",
        "\n",
        "for p in model.parameters():\n",
        "  p.requires_grad=True"
      ],
      "metadata": {
        "id": "a-RAu05b2HQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "\n",
        "max_steps = 200000\n",
        "lossi = []\n",
        "\n",
        "for i in range(max_steps):\n",
        "\n",
        "  # mini-batch\n",
        "  ix = torch.randint(0, Xtr.shape[0], (32,))\n",
        "  Xb, Yb = Xtr[ix], Ytr[ix]\n",
        "\n",
        "  # forward pass\n",
        "  x = Xb\n",
        "  logits = model(x)\n",
        "  loss = F.cross_entropy(logits, Yb)\n",
        "\n",
        "  # backward pass\n",
        "  for p in model.parameters():\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  # update\n",
        "  lr = 0.1 if i<150000 else 0.05\n",
        "  for p in model.parameters():\n",
        "    p.data += - lr * p.grad\n",
        "\n",
        "  # track stats\n",
        "  if i%10000==0:\n",
        "    print(f'{i}th iteration: loss {loss.item()}')\n",
        "  lossi.append(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0p1bdrFU2llb",
        "outputId": "a7014b3e-2237-4da4-be9c-7fa3254e3d21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0th iteration: loss 3.977170467376709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(torch.tensor(lossi).view(-1, 10000).mean(1))"
      ],
      "metadata": {
        "id": "2tSEPdhC4Nlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "  if isinstance(layer, BatchNorm1d):\n",
        "    layer.training = False"
      ],
      "metadata": {
        "id": "YCnkrhmTSnfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample from the model\n",
        "\n",
        "for i in range(20):\n",
        "  out = []\n",
        "  context = [0]*context_size\n",
        "  while True:\n",
        "    logits = model(torch.tensor([context]))\n",
        "    probs = F.softmax(logits, dim=1)\n",
        "    ix = torch.multinomial(probs, num_samples=1).item()\n",
        "\n",
        "    if ix==0:\n",
        "      break\n",
        "\n",
        "    out.append(ix)\n",
        "    context = context[1:] + [ix]\n",
        "\n",
        "  print(\"\".join(itos[x] for x in out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMPuraZn4htu",
        "outputId": "c0a612d0-6c3d-42ad-d60d-6ad9fec4203f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hicon\n",
            "frayx\n",
            "jakoo\n",
            "tefya\n",
            "rastin\n",
            "avyanna\n",
            "jenayx\n",
            "cocthelie\n",
            "aryla\n",
            "hankh\n",
            "graleit\n",
            "dahik\n",
            "demigi\n",
            "kenson\n",
            "matarie\n",
            "eliana\n",
            "daithu\n",
            "ariven\n",
            "gdory\n",
            "haise\n"
          ]
        }
      ]
    }
  ]
}